{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21506c0-8a6a-429e-ae65-a9acd24e4c19",
   "metadata": {},
   "source": [
    "### What is the relationship between the average price of gasoline and the cost of electricity per kilowatt-hour, what model(s) can be used to make accurate predictions of future gas prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5deccc-5c29-4910-9baa-d44ff6a8d2f4",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f65dc6-486f-4ca0-b8a0-729acbea893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load datasets\n",
    "gasoline_data_path = 'gasoline_data.csv'\n",
    "electric_data_path = 'electric_data.csv'\n",
    "\n",
    "gasoline_data = pd.read_csv(gasoline_data_path)\n",
    "electric_data = pd.read_csv(electric_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d6d58-29ff-401b-9343-c0795c3a193b",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36b5d1-faac-4ffb-a5a9-4ea7742a74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into proper columns\n",
    "gasoline_data_clean = gasoline_data['series_id        \\tyear\\tperiod\\t       value\\tfootnote_codes'].str.split('\\t', expand=True)\n",
    "electric_data_clean = electric_data['series_id        \\tyear\\tperiod\\t       value\\tfootnote_codes'].str.split('\\t', expand=True)\n",
    "\n",
    "# rename columns\n",
    "gasoline_columns = ['Series ID', 'Year', 'Period', 'Gasoline Price', 'Footnote Codes']\n",
    "electric_columns = ['Series ID', 'Year', 'Period', 'Electricity Price', 'Footnote Codes']\n",
    "\n",
    "gasoline_data_clean.columns = gasoline_columns\n",
    "electric_data_clean.columns = electric_columns\n",
    "\n",
    "# remove whitespace\n",
    "gasoline_data_clean = gasoline_data_clean.apply(lambda x: x.str.strip())\n",
    "electric_data_clean = electric_data_clean.apply(lambda x: x.str.strip())\n",
    "\n",
    "# handle '-' entries\n",
    "gasoline_data_clean['Gasoline Price'] = pd.to_numeric(gasoline_data_clean['Gasoline Price'], errors='coerce')\n",
    "electric_data_clean['Electricity Price'] = pd.to_numeric(electric_data_clean['Electricity Price'], errors='coerce')\n",
    "\n",
    "# check missing values\n",
    "gasoline_missing = gasoline_data_clean.isnull().sum()\n",
    "electric_missing = electric_data_clean.isnull().sum()\n",
    "\n",
    "# display count of missing values (0 means none)\n",
    "gasoline_missing, electric_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9acf20-d013-426a-9363-995d4bc73b79",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd119308-ff1f-4280-8051-e677f3837f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats for both datasets\n",
    "gasoline_stats = gasoline_data_clean.describe()\n",
    "electric_stats = electric_data_clean.describe()\n",
    "\n",
    "# period to months\n",
    "gasoline_data_clean['Month'] = gasoline_data_clean['Period'].str.replace('M', '').astype(int)\n",
    "electric_data_clean['Month'] = electric_data_clean['Period'].str.replace('M', '').astype(int)\n",
    "gasoline_data_clean['Date'] = pd.to_datetime(gasoline_data_clean[['Year', 'Month']].assign(DAY=1))\n",
    "electric_data_clean['Date'] = pd.to_datetime(electric_data_clean[['Year', 'Month']].assign(DAY=1))\n",
    "\n",
    "# Since the granularity is monthly, we'll average monthly prices for a direct comparison\n",
    "gasoline_monthly_avg = gasoline_data_clean.groupby('Date')['Gasoline Price'].mean().reset_index()\n",
    "electric_monthly_avg = electric_data_clean.groupby('Date')['Electricity Price'].mean().reset_index()\n",
    "\n",
    "# merge\n",
    "merged_data = pd.merge(gasoline_monthly_avg, electric_monthly_avg, on='Date', how='inner')\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(merged_data['Date'], merged_data['Gasoline Price'], label='Gasoline Price ($/gallon)', color='blue')\n",
    "plt.plot(merged_data['Date'], merged_data['Electricity Price'], label='Electricity Price ($/kWh)', color='green')\n",
    "plt.title('Monthly Average Gasoline and Electricity Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "gasoline_stats, electric_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911635e0-f80d-423e-8830-64fe8ec27a76",
   "metadata": {},
   "source": [
    "### Working with straightforward data (time and price), dimensionality reduction might not add value. More well-suited for datasets with large amounts of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d2921-2da0-444e-be9e-bedbcefa9913",
   "metadata": {},
   "source": [
    "### Going to need more features for a more robust model. Adding some more features: (WTI Crude Oil Historical Data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946458d-59d8-4366-9f13-6fd73e049115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing crude oil data for merged_data\n",
    "wti_data = pd.read_csv('wti-crudeoil.csv', names=['Date', 'WTI Oil Price'], header=0)\n",
    "wti_data['Date'] = pd.to_datetime(wti_data['Date'])\n",
    "wti_data['Year'] = wti_data['Date'].dt.year\n",
    "wti_data['Month'] = wti_data['Date'].dt.month\n",
    "wti_monthly_avg = wti_data.groupby(['Year', 'Month'])['WTI Oil Price'].mean().reset_index()\n",
    "wti_monthly_avg['Date'] = pd.to_datetime(wti_monthly_avg[['Year', 'Month']].assign(Day=1))\n",
    "wti_monthly_avg = wti_monthly_avg[['Date', 'WTI Oil Price']]\n",
    "merged_data = pd.merge(merged_data, wti_monthly_avg, on='Date', how='left')\n",
    "\n",
    "# processing unemployment data for merged_data\n",
    "unemployment_data = pd.read_csv('unemployment.csv', names=['Date', 'Unemployment Rate'], header=0)\n",
    "unemployment_data['Date'] = pd.to_datetime(unemployment_data['Date'])\n",
    "unemployment_data['Year'] = unemployment_data['Date'].dt.year\n",
    "unemployment_data['Month'] = unemployment_data['Date'].dt.month\n",
    "unemployment_data['Date'] = pd.to_datetime(unemployment_data[['Year', 'Month']].assign(Day=1))\n",
    "unemployment_data = unemployment_data[['Date', 'Unemployment Rate']]\n",
    "merged_data = pd.merge(merged_data, unemployment_data, on='Date', how='left')\n",
    "\n",
    "# oil and gas employee data for merged_data\n",
    "employee_data = pd.read_csv('oil_and_gas_employees.csv', names=['Date', 'Employees'], header=0)\n",
    "employee_data['Date'] = pd.to_datetime(employee_data['Date'])\n",
    "employee_data['Year'] = employee_data['Date'].dt.year\n",
    "employee_data['Month'] = employee_data['Date'].dt.month\n",
    "employee_data['Date'] = pd.to_datetime(employee_data[['Year', 'Month']].assign(Day=1))\n",
    "employee_data = employee_data[['Date', 'Employees']]\n",
    "merged_data = pd.merge(merged_data, employee_data, on='Date', how='left')\n",
    "\n",
    "# Check for missing values\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "# Impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X = merged_data[['Electricity Price', 'WTI Oil Price', 'Unemployment Rate', 'Employees']]\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "\n",
    "y = merged_data['Gasoline Price']\n",
    "\n",
    "# Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Examine model coefficients (and sort by absolute value)\n",
    "coef_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "coef_df['CoefMagnitude'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='CoefMagnitude', ascending=False)\n",
    "coef_df.drop(columns=['CoefMagnitude'], inplace=True)\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd8f0a-84aa-4452-9540-b403a4d37dc3",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488afb0f-f908-4307-af64-96277328230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the linear regression model\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_r2 = r2_score(y_test, lr_y_pred)\n",
    "\n",
    "print(\"Linear Regression Model:\")\n",
    "print(f\"Root Mean Squared Error: {lr_rmse:.2f}\")\n",
    "print(f\"R-squared: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26bf79-629f-4593-b7ef-b9b5be13ea6b",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dff8d0-9fb9-452f-b5fb-6e95cabf0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9ab26-0f4f-4f55-b6af-35a8a8dbf5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit a KNN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "knn_y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "knn_mse = mean_squared_error(y_test, knn_y_pred)\n",
    "knn_rmse = np.sqrt(knn_mse)\n",
    "knn_r2 = r2_score(y_test, knn_y_pred)\n",
    "\n",
    "print(\"\\nKNN Model:\")\n",
    "print(f\"Root Mean Squared Error: {knn_rmse:.2f}\")\n",
    "print(f\"R-squared: {knn_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0a01b-4644-4540-ad24-f9cc329bd2da",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b26e64-9112-4aa8-a310-3d56a539c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision Tree model\n",
    "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "dt_y_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "dt_mse = mean_squared_error(y_test, dt_y_pred)\n",
    "dt_rmse = np.sqrt(dt_mse)\n",
    "dt_r2 = r2_score(y_test, dt_y_pred)\n",
    "\n",
    "print(\"\\nDecision Tree Model:\")\n",
    "print(f\"Root Mean Squared Error: {dt_rmse:.2f}\")\n",
    "print(f\"R-squared: {dt_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b465-85a3-482b-acf0-5b85f43a5188",
   "metadata": {},
   "source": [
    "### Linear regression displayed a moderate fit to the data. (RMSE: 0.36, R-squared: 0.88)\n",
    "### KNN displayed a very good fit to the data. (RMSE: 0.19, R-squared: 0.97)\n",
    "### Decision tree also displayed a very good fit to the data. (RMSE: 0.17, R-squared: 0.97).\n",
    "The Decision tree model and the KNN modelâ€™s results suggest that they were able to find these interactions and nonlinear relationships between the features that we were looking for. In summary, the KNN and Decision Tree models were able to capture the more complex relationships in the data and provided much better predictions of our target variable, gas prices. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e9519-842a-4c9d-9f74-49bf22826857",
   "metadata": {},
   "source": [
    "## Validating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c9026-9575-460c-a5f0-8bca6662f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Linear Regression\n",
    "lr_scores = cross_val_score(lr_model, X_scaled, y, cv=5, scoring='r2')\n",
    "print(f\"Linear Regression Cross-Validation R^2 Scores: {lr_scores}\")\n",
    "print(f\"Linear Regression Average Cross-Validation R^2 Score: {lr_scores.mean():.2f}\")\n",
    "\n",
    "# KNN\n",
    "knn_scores = cross_val_score(knn_model, X_scaled, y, cv=5, scoring='r2')\n",
    "print(f\"\\nKNN Cross-Validation R^2 Scores: {knn_scores}\")\n",
    "print(f\"KNN Average Cross-Validation R^2 Score: {knn_scores.mean():.2f}\")\n",
    "\n",
    "# Decision Tree\n",
    "dt_scores = cross_val_score(dt_model, X_scaled, y, cv=5, scoring='r2')\n",
    "print(f\"\\nDecision Tree Cross-Validation R^2 Scores: {dt_scores}\")\n",
    "print(f\"Decision Tree Average Cross-Validation R^2 Score: {dt_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b19e1b-943a-4e27-9cdb-2c66f49c07c1",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8669c10-ae14-4300-8f59-a86161fc2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Linear Regression\n",
    "axes[0].scatter(y_test, lr_y_pred)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "axes[0].set_xlabel('Measured')\n",
    "axes[0].set_ylabel('Predicted')\n",
    "axes[0].set_title('Linear Regression')\n",
    "\n",
    "# KNN\n",
    "axes[1].scatter(y_test, knn_y_pred)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "axes[1].set_xlabel('Measured')\n",
    "axes[1].set_ylabel('Predicted')\n",
    "axes[1].set_title('KNN')\n",
    "\n",
    "# Decision Tree\n",
    "axes[2].scatter(y_test, dt_y_pred)\n",
    "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "axes[2].set_xlabel('Measured')\n",
    "axes[2].set_ylabel('Predicted')\n",
    "axes[2].set_title('Decision Tree')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
